{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1sZLWBh-U5HBa3TenmsszMDsXxJvLxEng",
      "authorship_tag": "ABX9TyO/gUbQ6Y3XMY2D26rzOoUR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanmzeidler/HI744_Programming_Assignment_1/blob/main/Zeidler_Programming_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs, downloads, and imports"
      ],
      "metadata": {
        "id": "q1PeB9VMUj4e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qQ3idEXQXdo",
        "outputId": "678e84fc-de77-42c7-df62-17c51a0a411f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44ttlXJaTpFw",
        "outputId": "522002ba-1de6-4839-a311-8d202cde5137"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Util Functions"
      ],
      "metadata": {
        "id": "Hw00rjzyVMqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Provided by Professor He\n",
        "import nltk\n",
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import json\n",
        "import sys\n",
        "\n",
        "def read_txt_files_from_directory(directory_path):\n",
        "    file_contents = {}\n",
        "    try:\n",
        "        for filename in os.listdir(directory_path):\n",
        "            if filename.endswith('.txt'):\n",
        "                file_path = os.path.join(directory_path, filename)\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                        file_contents[filename] = file.read()\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred while reading {filename}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while accessing the directory: {e}\")\n",
        "        return {}\n",
        "    return file_contents\n",
        "\n",
        "def load_from_json(filename):\n",
        "    try:\n",
        "        with open(filename, 'r') as json_file:\n",
        "            data = json.load(json_file)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "        return None\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    return tokenizer.tokenize(text)\n",
        "\n",
        "def remove_stop_words(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_sentence = []\n",
        "    for token in tokens:\n",
        "        if token not in stop_words:\n",
        "            filtered_sentence.append(token)\n",
        "    return filtered_sentence\n",
        "\n",
        "def stemming(tokens):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "def pre_process(text):\n",
        "    text_lower = text.lower()\n",
        "    tokens_no_punctuation = remove_punctuation(text_lower)\n",
        "    filtered_tokens = remove_stop_words(tokens_no_punctuation)\n",
        "    stemmed_tokens = stemming(filtered_tokens)\n",
        "    return stemmed_tokens"
      ],
      "metadata": {
        "id": "LWp86ThuVSbe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def top_5(vector_matrix, data, column_name):\n",
        "  sim_matrix = cosine_similarity(vector_matrix)\n",
        "  top5_indices = np.argpartition(-sim_matrix, range(6), axis=1)[:, 1:6].tolist()\n",
        "  data[column_name] = top5_indices\n",
        "  data[column_name] = data[column_name].apply(lambda x: id_list(data,x))\n",
        "\n",
        "def id_list(data,index_list):\n",
        "  id_list = []\n",
        "  for i in index_list:\n",
        "    id_list.append(data.at[i,'patient_uid'])\n",
        "  return id_list\n"
      ],
      "metadata": {
        "id": "gfqdR3Ne8p00"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Similarity"
      ],
      "metadata": {
        "id": "ejD8_ufEwCzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_similarity(data):\n",
        "  tfidf = TfidfVectorizer()\n",
        "  vector_matrix = tfidf.fit_transform(data['patient'])\n",
        "  top_5(vector_matrix, data, 'top5_tfidf')"
      ],
      "metadata": {
        "id": "WwuQ3gU-wGIp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec Similarity"
      ],
      "metadata": {
        "id": "D1fQVKosv-xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.test.utils import get_tmpfile\n",
        "\n",
        "def load_dataset(fname,nrows=1000):\n",
        "  data = safe_read_csv(fname,nrows)\n",
        "  data['tokens'] = data['patient'].apply(lambda text: pre_process(text))\n",
        "  print(\"Data loaded\")\n",
        "  return data\n",
        "\n",
        "def safe_read_csv(fname,nrows):\n",
        "  try:\n",
        "    filepath = os.path.join(PROJ_DIRECTORY,fname)\n",
        "    return pd.read_csv(filepath_or_buffer=filepath,nrows=nrows)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while reading the file: {e}\")\n",
        "    return None\n",
        "\n",
        "#Adapted from https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py\n",
        "def read_corpus(data, tokens_only = False):\n",
        "    documents = data['tokens']\n",
        "    for i, tokens in documents.items():\n",
        "        if tokens_only:\n",
        "            yield tokens\n",
        "        else:\n",
        "            # For training data, add tags\n",
        "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
        "\n",
        "def train_doc2vec(data):\n",
        "  model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=1, epochs=40)\n",
        "  train_corpus = list(read_corpus(data))\n",
        "  test_corpus = list(read_corpus(data, tokens_only=True))\n",
        "  model.build_vocab(train_corpus)\n",
        "  print(\"Vocab built\")\n",
        "  print(\"Starting training\")\n",
        "  model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "  fname = get_tmpfile(os.path.join(PROJ_DIRECTORY,\"my_doc2vec_model\"))\n",
        "  model.save(fname)\n",
        "  print(\"Model saved\")\n",
        "  return model\n",
        "\n",
        "def doc2vec_vectors(model, data):\n",
        "  vector_matrix = []\n",
        "  print(\"Calcualting Doc2Vec vectors\")\n",
        "  for _ , tokens in data['tokens'].items():\n",
        "    vector_matrix.append(np.array(model.infer_vector(tokens)))\n",
        "  print(\"Vectors calculated\")\n",
        "  return vector_matrix\n",
        "\n",
        "\n",
        "def load_model(fname):\n",
        "  return Doc2Vec.load(fname)\n",
        "\n",
        "def doc2vec_similarity(data):\n",
        "  doc2vec_model = train_doc2vec(data)\n",
        "  vector_matrix = doc2vec_vectors(doc2vec_model,data)\n",
        "  top_5(vector_matrix, data,'top5_doc2vec')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9OBmUsM-WgAn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJ_DIRECTORY =\"/content/drive/MyDrive/HI744_Programming_Assignment_1\"\n",
        "data = load_dataset(\"PMC-Patients.csv\")\n",
        "doc2vec_similarity(data)\n",
        "print(data.head())\n",
        "tfidf_similarity(data)\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YVOmNrXX1bq",
        "outputId": "8e973949-b877-4490-b4c0-7056d17c6db4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded\n",
            "Vocab built\n",
            "Starting training\n",
            "Model saved\n",
            "Calcualting Doc2Vec vectors\n",
            "Vectors calculated\n",
            "   patient_id patient_uid      PMID                         file_path  \\\n",
            "0           0   7665777-1  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "1           1   7665777-2  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "2           2   7665777-3  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "3           3   7665777-4  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "4           4   7665777-5  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "\n",
            "                                               title  \\\n",
            "0  Early Physical Therapist Interventions for Pat...   \n",
            "1  Early Physical Therapist Interventions for Pat...   \n",
            "2  Early Physical Therapist Interventions for Pat...   \n",
            "3  Early Physical Therapist Interventions for Pat...   \n",
            "4  Early Physical Therapist Interventions for Pat...   \n",
            "\n",
            "                                             patient               age gender  \\\n",
            "0  This 60-year-old male was hospitalized due to ...  [[60.0, 'year']]      M   \n",
            "1  A 39-year-old man was hospitalized due to an i...  [[39.0, 'year']]      M   \n",
            "2  One week after a positive COVID-19 result this...  [[57.0, 'year']]      M   \n",
            "3  This 69-year-old male was admitted to the ICU ...  [[69.0, 'year']]      M   \n",
            "4  This 57-year-old male was admitted to the ICU ...  [[57.0, 'year']]      M   \n",
            "\n",
            "                                   relevant_articles  \\\n",
            "0  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "1  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "2  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "3  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "4  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "\n",
            "                                    similar_patients  \\\n",
            "0  {'7665777-2': 2, '7665777-3': 2, '7665777-4': ...   \n",
            "1  {'7665777-1': 2, '7665777-3': 2, '7665777-4': ...   \n",
            "2  {'7665777-1': 2, '7665777-2': 2, '7665777-4': ...   \n",
            "3  {'7665777-1': 2, '7665777-2': 2, '7665777-3': ...   \n",
            "4  {'7665777-1': 2, '7665777-2': 2, '7665777-3': ...   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  [60, year, old, male, hospit, due, moder, ard,...   \n",
            "1  [39, year, old, man, hospit, due, increasingli...   \n",
            "2  [one, week, posit, covid, 19, result, 57, year...   \n",
            "3  [69, year, old, male, admit, icu, dri, cough, ...   \n",
            "4  [57, year, old, male, admit, icu, dyspnea, hea...   \n",
            "\n",
            "                                        top5_doc2vec  \n",
            "0  [7665777-3, 7665777-2, 7665777-7, 7665777-10, ...  \n",
            "1  [7665777-3, 7665777-7, 7665777-8, 7665777-10, ...  \n",
            "2  [7665777-2, 7665777-9, 7665777-7, 7665777-1, 7...  \n",
            "3  [7665777-9, 7665777-3, 7665777-10, 7665777-7, ...  \n",
            "4  [7665777-10, 7665777-7, 7665777-3, 7665777-2, ...  \n",
            "   patient_id patient_uid      PMID                         file_path  \\\n",
            "0           0   7665777-1  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "1           1   7665777-2  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "2           2   7665777-3  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "3           3   7665777-4  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "4           4   7665777-5  33492400  comm/PMC007xxxxxx/PMC7665777.xml   \n",
            "\n",
            "                                               title  \\\n",
            "0  Early Physical Therapist Interventions for Pat...   \n",
            "1  Early Physical Therapist Interventions for Pat...   \n",
            "2  Early Physical Therapist Interventions for Pat...   \n",
            "3  Early Physical Therapist Interventions for Pat...   \n",
            "4  Early Physical Therapist Interventions for Pat...   \n",
            "\n",
            "                                             patient               age gender  \\\n",
            "0  This 60-year-old male was hospitalized due to ...  [[60.0, 'year']]      M   \n",
            "1  A 39-year-old man was hospitalized due to an i...  [[39.0, 'year']]      M   \n",
            "2  One week after a positive COVID-19 result this...  [[57.0, 'year']]      M   \n",
            "3  This 69-year-old male was admitted to the ICU ...  [[69.0, 'year']]      M   \n",
            "4  This 57-year-old male was admitted to the ICU ...  [[57.0, 'year']]      M   \n",
            "\n",
            "                                   relevant_articles  \\\n",
            "0  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "1  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "2  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "3  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "4  {'32320506': 1, '32293716': 1, '23219649': 1, ...   \n",
            "\n",
            "                                    similar_patients  \\\n",
            "0  {'7665777-2': 2, '7665777-3': 2, '7665777-4': ...   \n",
            "1  {'7665777-1': 2, '7665777-3': 2, '7665777-4': ...   \n",
            "2  {'7665777-1': 2, '7665777-2': 2, '7665777-4': ...   \n",
            "3  {'7665777-1': 2, '7665777-2': 2, '7665777-3': ...   \n",
            "4  {'7665777-1': 2, '7665777-2': 2, '7665777-3': ...   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  [60, year, old, male, hospit, due, moder, ard,...   \n",
            "1  [39, year, old, man, hospit, due, increasingli...   \n",
            "2  [one, week, posit, covid, 19, result, 57, year...   \n",
            "3  [69, year, old, male, admit, icu, dri, cough, ...   \n",
            "4  [57, year, old, male, admit, icu, dyspnea, hea...   \n",
            "\n",
            "                                        top5_doc2vec  \\\n",
            "0  [7665777-3, 7665777-2, 7665777-7, 7665777-10, ...   \n",
            "1  [7665777-3, 7665777-7, 7665777-8, 7665777-10, ...   \n",
            "2  [7665777-2, 7665777-9, 7665777-7, 7665777-1, 7...   \n",
            "3  [7665777-9, 7665777-3, 7665777-10, 7665777-7, ...   \n",
            "4  [7665777-10, 7665777-7, 7665777-3, 7665777-2, ...   \n",
            "\n",
            "                                          top5_tfidf  \n",
            "0  [7665777-3, 7665777-2, 7665777-7, 6011174-1, 8...  \n",
            "1  [7665777-1, 7665777-3, 6004679-1, 6011170-1, 6...  \n",
            "2  [7665777-1, 7665777-2, 7665777-7, 6011174-1, 8...  \n",
            "3  [7665777-3, 7665777-9, 8698451-1, 7665777-7, 7...  \n",
            "4  [7665777-11, 7665777-9, 7665777-10, 7665777-3,...  \n"
          ]
        }
      ]
    }
  ]
}